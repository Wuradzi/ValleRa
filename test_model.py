#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–∏–π —Ç–µ—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ Ollama —Ç–∞ –º–æ–¥–µ–ª—ñ
"""
import requests
import config

def test_ollama():
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ Ollama –∑–∞–ø—É—â–µ–Ω–∏–π"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json()['models']
            print("‚úÖ Ollama –∑–∞–ø—É—â–µ–Ω–∏–π!")
            print(f"üì¶ –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)}")
            for model in models:
                print(f"  - {model['name']}")
            return True
        else:
            print("‚ùå Ollama –Ω–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î.")
            return False
    except Exception as e:
        print(f"‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π: {e}")
        print("üí° –ó–∞–ø—É—Å—Ç—ñ—Ç—å: ollama serve")
        return False

def test_model():
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –º–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–æ—Å—Ç–æ–º—É –∑–∞–ø–∏—Ç—ñ"""
    try:
        import ollama
        
        model_name = config.LOCAL_MODEL_LIGHT
        print(f"\nüß™ –¢–µ—Å—Ç—É—é –º–æ–¥–µ–ª—å {model_name}...")
        
        response = ollama.chat(
            model=model_name,
            messages=[{'role': 'user', 'content': '–ü—Ä–∏–≤—ñ—Ç! –Ø–∫ —Ç–≤–æ—î —ñ–º\'—è?'}],
            stream=False
        )
        
        answer = response['message']['content']
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î!")
        print(f"ü§ñ –ú–æ–¥–µ–ª—å –∫–∞–∂–µ: {answer}\n")
        return True
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –º–æ–¥–µ–ª—ñ: {e}")
        return False

if __name__ == "__main__":
    print("=" * 50)
    print("üîç –¢–µ—Å—Ç Ollama —Ç–∞ –º–æ–¥–µ–ª—ñ ValleRa")
    print("=" * 50)
    
    if test_ollama():
        test_model()
    
    print("=" * 50)
    print("‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
